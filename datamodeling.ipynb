{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('metis': conda)",
   "display_name": "Python 3.8.3 64-bit ('metis': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e94c15d6dbef08e95baaf638ff93666d2390f58e0c4317ae3b2bf35ecad0e12e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickles : gini_table, demo2018, margins2018, area table, comp table, rural table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_table = pd.read_pickle('gini_table')\n",
    "demo2018 = pd.read_pickle('demo2018')\n",
    "margins2018 = pd.read_pickle('margins2018')\n",
    "area_table = pd.read_pickle('area_table')\n",
    "comp_table = pd.read_pickle('comp_table')\n",
    "rural_table = pd.read_pickle('rural_table')\n",
    "gerry_index = pd.read_pickle('gerryindex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerry_index.sort_values(by=['district']).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging  Tables\n",
    "df = margins2018.merge(gini_table, left_on='district', right_on='district')\n",
    "df = df.merge(rural_table, left_on='district', right_on='district')\n",
    "df = df.drop(['state'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(area_table, left_on='district', right_on='district')\n",
    "df = df.merge(demo2018, left_on='district', right_on='Code')\n",
    "df = df.merge(gerry_index, left_on='district', right_on='district')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = df.set_index('district')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.rename(columns={'Land area (miÂ²)':'land_area_mi'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format numbers to numeric\n",
    "dfa['land_area_mi'] = dfa['land_area_mi'].apply(lambda x: float(x.replace(',','')))\n",
    "dfa['median_income'] = dfa['median_income'].apply(lambda x: x.replace('$',''))\n",
    "dfa['median_income'] = dfa['median_income'].apply(lambda x: float(x.replace(',','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa[['land_area_mi', 'median_income']] = dfa[['land_area_mi', 'median_income']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfamod = dfa.drop(['2016 Clinton Margin', 'clinton2016', 'trump2016', 'obama2012', 'romney2012', '2016dem', '2016rep', '2014dem', '2014rep','state', 'Code', 'First Elected', 'Birth Year', 'LGBTQ', '2018dem', '2018rep'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfamod1 = dfamod.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical incumbent \n",
    "dfamod1['Pre-2018 Incumbent'] = dfamod1['Pre-2018 Incumbent'].apply(lambda x: 1 if x == 'Won' else 0)\n",
    "\n",
    "# narrowing religions \n",
    "dfamod1['Religion'] = dfamod1['Religion'].apply(lambda x: 'catholic' if x == 'Christian - Roman Catholic' or x == 'Christian - Chaldean Catholic' else 'mormon' if x == 'Christian - Mormon' else 'jewish' if x == 'Jewish' else 'other' if x == 'Unknown/Refused' or x == 'Muslim' or x == 'Buddhist - Soka Gakkai' or x == 'Hindu' else 'protestant')\n",
    "\n",
    "# narrowing race\n",
    "dfamod1['Race/ Ethnicity'] = dfamod1['Race/ Ethnicity'].apply(lambda x: 'white' if x == 'White - Non-Hispanic' else 'non_white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc density\n",
    "dfamod1['density'] = dfamod1['population'] / dfamod1['land_area_mi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populations should be roughly equal\n",
    "dfamod1 = dfamod1.drop(['population'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfadumf.to_csv('dfmain.csv')\n",
    "df1 = pd.read_csv('dfmain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(25,15))\n",
    "# cor_plot = sns.heatmap(df1.corr().round(4), cmap='seismic', annot=True, vmin=-1, vmax=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns_plot = sns.pairplot(dfamod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns_plot.savefig('pair.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set dummies\n",
    "dfadum = pd.get_dummies(dfamod1)\n",
    "dfadum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfadumf = dfadum.fillna(dfadum.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set features and target for modeling \n",
    "features = [c for c in dfadum if c != 'Dem Margin']\n",
    "\n",
    "X = dfadumf[features]\n",
    "y = dfadumf['Dem Margin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_results(X, y, model=LinearRegression(normalize=True), scoring='r2', rounding=4, cv=5, minimize_score=False):\n",
    "    '''\n",
    "    For a set of features and target X, y, perform a 5 fold cross validation.\n",
    "    Fit and validate a model, and report results\n",
    "    Note: `sklearn.model_selection.cross_validate` defaults to 5 fold, 80/20 validation splits.\n",
    "    '''\n",
    "    \n",
    "    model_cv = cross_validate(model, X, y, cv=cv, return_train_score=True, \n",
    "                              scoring=scoring, return_estimator=True)\n",
    "\n",
    "    if minimize_score:\n",
    "        select = model_cv['test_score'].argmin()\n",
    "    else:\n",
    "        select = model_cv['test_score'].argmax()\n",
    "\n",
    "    final_model = model_cv['estimator'][select]\n",
    "    \n",
    "    # Capture the ratio between the train and test scores to understand possible under/over fitting\n",
    "    model_cv['train_test_score_ratio'] = model_cv['train_score'] / model_cv['test_score']\n",
    "    \n",
    "    mean_score = round(model_cv['test_score'].mean(), rounding)\n",
    "    min_score = round(model_cv['test_score'].min(), rounding)\n",
    "    max_score = round(model_cv['test_score'].max(), rounding)\n",
    "    \n",
    "    mean_ratio = round(model_cv['train_test_score_ratio'].mean(), rounding)\n",
    "    min_ratio = round(model_cv['train_test_score_ratio'].min(), rounding)\n",
    "    max_ratio = round(model_cv['train_test_score_ratio'].max(), rounding)\n",
    "    \n",
    "    # report results\n",
    "    print(f'Test {scoring} {\":\":<15} Mean = {mean_score}\\tRange = ({min_score}, {max_score})')\n",
    "    print(f'Train/Test {scoring} Ratio {\":\":<3} Mean = {mean_ratio}\\tRange = ({min_ratio}, {max_ratio})')\n",
    "    \n",
    "    print('\\nBest Model Feature coefficient results:')\n",
    "    for feature, coef in zip(X.columns, final_model.coef_):\n",
    "        print(f'{feature + \":\":<16} {coef:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "\n",
    "#Feature scaling for train, val, and test so that we can run our ridge model on each\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "X_val_scaled = scaler.transform(X_val.values)\n",
    "X_test_scaled = scaler.transform(X_test.values)\n",
    "\n",
    "lm_reg = Ridge(alpha=1)\n",
    "\n",
    "#Feature transforms for train, val, and test so that we can run our poly model on each\n",
    "poly = PolynomialFeatures(degree=2) \n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train.values)\n",
    "X_val_poly = poly.transform(X_val.values)\n",
    "X_test_poly = poly.transform(X_test.values)\n",
    "\n",
    "lm_poly = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X_train, y_train)\n",
    "print(f'Linear Regression val R^2: {lm.score(X_val, y_val):.3f}')\n",
    "\n",
    "lm_reg.fit(X_train_scaled, y_train)\n",
    "print(f'Ridge Regression val R^2: {lm_reg.score(X_val_scaled, y_val):.3f}')\n",
    "\n",
    "lm_poly.fit(X_train_poly, y_train)\n",
    "print(f'Degree 2 polynomial regression val R^2: {lm_poly.score(X_val_poly, y_val):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array for kfold\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state = 71)\n",
    "cv_lm_r2s, cv_lm_reg_r2s = [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm = LinearRegression()\n",
    "    lm_reg = Ridge(alpha=1)\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    cv_lm_r2s.append(lm.score(X_val, y_val))\n",
    "    \n",
    "    #ridge with feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    lm_reg.fit(X_train_scaled, y_train)\n",
    "    cv_lm_reg_r2s.append(lm_reg.score(X_val_scaled, y_val))\n",
    "\n",
    "print('Simple regression scores: ', cv_lm_r2s)\n",
    "print('Ridge scores: ', cv_lm_reg_r2s, '\\n')\n",
    "\n",
    "print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')\n",
    "print(f'Ridge mean cv r^2: {np.mean(cv_lm_reg_r2s):.3f} +- {np.std(cv_lm_reg_r2s):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lm_reg = Ridge(alpha=1)\n",
    "lm_reg.fit(X_scaled,y)\n",
    "print(f'Ridge Regression test R^2: {lm_reg.score(X_test_scaled, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STATS MODELS\n",
    "X = dfadumf[features]\n",
    "y = dfadumf['Dem Margin']\n",
    "\n",
    "model = sm.OLS(y, sm.add_constant(X)) \n",
    "\n",
    "fit = model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ridge lasso\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "std.fit(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = std.transform(X_train.values)\n",
    "X_te = std.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphavec = 10**np.linspace(-2,2,200)\n",
    "\n",
    "lasso_model = LassoCV(alphas = alphavec, cv=5)\n",
    "lasso_model.fit(X_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, lasso_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphavec = 10**np.linspace(-2,2,200)\n",
    "\n",
    "ridge_model = RidgeCV(alphas = alphavec, cv=5)\n",
    "ridge_model.fit(X_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, ridge_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminating columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### round again\n",
    "keep = ['gini', 'per_urban', 'blackper', 'bach_higher', '2016presmarg', '2012presmarg',\n",
    "        '2016marg', '2014marg', 'time_in_office', 'Party_Democratic']#, 'Religion_catholic', 'Religion_protestant']\n",
    "\n",
    "X = dfadumf[keep]\n",
    "y = dfadumf['Dem Margin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, sm.add_constant(X)) \n",
    "\n",
    "fit = model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "\n",
    "#Feature scaling for train, val, and test so that we can run our ridge model on each\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "X_val_scaled = scaler.transform(X_val.values)\n",
    "X_test_scaled = scaler.transform(X_test.values)\n",
    "\n",
    "lm_reg = Ridge(alpha=1)\n",
    "\n",
    "#Feature transforms for train, val, and test so that we can run our poly model on each\n",
    "poly = PolynomialFeatures(degree=2) \n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train.values)\n",
    "X_val_poly = poly.transform(X_val.values)\n",
    "X_test_poly = poly.transform(X_test.values)\n",
    "\n",
    "lm_poly = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X_train, y_train)\n",
    "print(f'Linear Regression val R^2: {lm.score(X_val, y_val):.3f}')\n",
    "\n",
    "lm_reg.fit(X_train_scaled, y_train)\n",
    "print(f'Ridge Regression val R^2: {lm_reg.score(X_val_scaled, y_val):.3f}')\n",
    "\n",
    "lm_poly.fit(X_train_poly, y_train)\n",
    "print(f'Degree 2 polynomial regression val R^2: {lm_poly.score(X_val_poly, y_val):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(X), np.array(y)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 71)\n",
    "cv_lm_r2s, cv_lm_reg_r2s = [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm = LinearRegression()\n",
    "    lm_reg = Ridge(alpha=1)\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    cv_lm_r2s.append(lm.score(X_val, y_val))\n",
    "    \n",
    "    #ridge with feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    lm_reg.fit(X_train_scaled, y_train)\n",
    "    cv_lm_reg_r2s.append(lm_reg.score(X_val_scaled, y_val))\n",
    "\n",
    "print('Simple regression scores: ', cv_lm_r2s)\n",
    "print('Ridge scores: ', cv_lm_reg_r2s, '\\n')\n",
    "\n",
    "print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')\n",
    "print(f'Ridge mean cv r^2: {np.mean(cv_lm_reg_r2s):.3f} +- {np.std(cv_lm_reg_r2s):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lm_reg = Ridge(alpha=1)\n",
    "lm_reg.fit(X_scaled,y)\n",
    "print(f'Ridge Regression test R^2: {lm_reg.score(X_test_scaled, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfadumf[keep]\n",
    "y = dfadumf['Dem Margin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "std.fit(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphavec = 10**np.linspace(-2,2,200)\n",
    "\n",
    "lasso_model = LassoCV(alphas = alphavec, cv=5)\n",
    "lasso_model.fit(X_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, lasso_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphavec = 10**np.linspace(-2,2,200)\n",
    "\n",
    "ridge_model = RidgeCV(alphas = alphavec, cv=5)\n",
    "ridge_model.fit(X_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, ridge_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 71)\n",
    "cv_lm_r2s, cv_lm_reg_r2s = [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm = LinearRegression()\n",
    "    lm_reg = Ridge(alpha=37.8)\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    cv_lm_r2s.append(lm.score(X_val, y_val))\n",
    "    \n",
    "    #ridge with feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    lm_reg.fit(X_train_scaled, y_train)\n",
    "    cv_lm_reg_r2s.append(lm_reg.score(X_val_scaled, y_val))\n",
    "\n",
    "print('Simple regression scores: ', cv_lm_r2s)\n",
    "print('Ridge scores: ', cv_lm_reg_r2s, '\\n')\n",
    "\n",
    "print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')\n",
    "print(f'Ridge mean cv r^2: {np.mean(cv_lm_reg_r2s):.3f} +- {np.std(cv_lm_reg_r2s):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lm_reg = Ridge(alpha=37.8)\n",
    "lm_reg.fit(X_scaled,y)\n",
    "print(f'Ridge Regression test R^2: {lm_reg.score(X_test_scaled, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lm_reg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(y_pred, y_test)\n",
    "plt.title('Y predicted vs Y test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Absolute Error (MAE)\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_pred - y_true)) \n",
    "\n",
    "mae(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "res = y_test - y_pred\n",
    "plt.scatter(y_test, res)\n",
    "plt.xlabel('Actual Margin')\n",
    "plt.ylabel('residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QQ plot\n",
    "plt.figure(figsize=(30,10))\n",
    "    \n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "\n",
    "stats.probplot(res, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfadumf.to_csv('dfmain.csv')\n",
    "df1 = pd.read_csv('dfmain.csv')"
   ]
  }
 ]
}